"""
NewsQuant ë§¤ë§¤ ì‹œê·¸ë„ ì„ê³„ê°’ ìµœì í™” (Grid Search)
==================================================
1) DBì—ì„œ ëª¨ë“  ë‚ ì§œë³„ ì¢…ëª© í†µê³„ë¥¼ ë¯¸ë¦¬ ì¶”ì¶œ
2) ëª¨ë“  í›„ë³´ ì¢…ëª©ì˜ ì£¼ê°€ë¥¼ í•œë²ˆì— í¬ë¡¤ë§ & ìºì‹œ
3) Grid searchë¡œ ì„ê³„ê°’ ì¡°í•©ë³„ ì„±ê³¼ í‰ê°€ (ìºì‹œë§Œ ì‚¬ìš©, ë¹ ë¦„)

ì‚¬ìš©ë²•:
    python scripts/optimize_thresholds.py
    python scripts/optimize_thresholds.py --start 2025-12-12 --end 2026-02-06
"""

import sys
import os
import argparse
import time
import json
import pickle
import logging
from pathlib import Path
from datetime import datetime, timedelta
from collections import defaultdict
from typing import Dict, List, Optional, Tuple
from itertools import product

PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from news_scraper.database import NewsDatabase
from news_scraper.price_fetcher import PriceFetcher

logging.basicConfig(level=logging.WARNING, format='%(message)s')
logger = logging.getLogger(__name__)

HOLDING_DAYS = [1, 3, 5, 7, 10]

# â”€â”€â”€ Grid search íŒŒë¼ë¯¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

BUY_GRID = {
    'avg_sentiment': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],
    'avg_overall': [0.3, 0.4, 0.5, 0.6],
    'news_count': [3, 5, 7, 10],
    'positive_ratio': [0.3, 0.5, 0.6, 0.7, 0.8],
}

SELL_GRID = {
    'avg_sentiment': [-0.05, -0.1, -0.15, -0.2, -0.25, -0.3],
    'avg_overall': [0.3, 0.25, 0.2, 0.15, 0.1],
    'news_count': [3, 5, 7, 10],
    'negative_ratio': [0.3, 0.5, 0.6, 0.7, 0.8],
}


# â”€â”€â”€ 1ë‹¨ê³„: ì „ì²´ ë‚ ì§œë³„ ì¢…ëª© í†µê³„ ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_all_stock_stats(db: NewsDatabase, start_date: str, end_date: str) -> Dict[str, List[Dict]]:
    """ë‚ ì§œë³„ ëª¨ë“  ì¢…ëª©ì˜ ë‰´ìŠ¤ í†µê³„ë¥¼ ì¶”ì¶œ. {date: [stock_stat, ...]}"""
    trading_days = get_trading_days(db, start_date, end_date)
    print(f"ğŸ“Š {len(trading_days)}ê°œ ê±°ë˜ì¼ì—ì„œ ì¢…ëª© í†µê³„ ì¶”ì¶œ ì¤‘...")

    daily_stats = {}
    for date in trading_days:
        stats = analyze_stocks_for_date(db, date)
        daily_stats[date] = stats
    
    total_stocks = sum(len(v) for v in daily_stats.values())
    print(f"   ì´ {total_stocks}ê±´ ì¢…ëª©-ë‚ ì§œ ì¡°í•© ì¶”ì¶œ ì™„ë£Œ")
    return daily_stats


def analyze_stocks_for_date(db: NewsDatabase, target_date: str) -> List[Dict]:
    """íŠ¹ì • ë‚ ì§œì˜ ëª¨ë“  ì¢…ëª© í†µê³„ (í•„í„°ë§ ì—†ì´)"""
    start = f"{target_date}T00:00:00"
    end = f"{target_date}T23:59:59.999999"
    today_news = db.get_news_by_date_range(start, end)

    if not today_news:
        return []

    stock_analysis = defaultdict(lambda: {
        'sentiment_scores': [], 'overall_scores': [],
        'positive_count': 0, 'negative_count': 0, 'news_count': 0,
    })

    for news in today_news:
        related_stocks = news.get('related_stocks', '')
        if not related_stocks:
            continue
        stocks = [s.strip() for s in related_stocks.split(',') if s.strip()]
        sentiment = news.get('sentiment_score')
        overall = news.get('overall_score')

        for code in stocks:
            if not (len(code) == 6 and code.isdigit()):
                continue
            sa = stock_analysis[code]
            sa['news_count'] += 1
            if sentiment is not None:
                sa['sentiment_scores'].append(sentiment)
                if sentiment > 0:
                    sa['positive_count'] += 1
                elif sentiment < 0:
                    sa['negative_count'] += 1
            if overall is not None:
                sa['overall_scores'].append(overall)

    results = []
    for code, data in stock_analysis.items():
        n = data['news_count']
        if n == 0:
            continue
        avg_sent = sum(data['sentiment_scores']) / len(data['sentiment_scores']) if data['sentiment_scores'] else 0.0
        avg_overall = sum(data['overall_scores']) / len(data['overall_scores']) if data['overall_scores'] else 0.0
        pos_ratio = data['positive_count'] / n if n > 0 else 0.0
        neg_ratio = data['negative_count'] / n if n > 0 else 0.0

        results.append({
            'stock_code': code,
            'news_count': n,
            'avg_sentiment': avg_sent,
            'avg_overall': avg_overall,
            'positive_count': data['positive_count'],
            'negative_count': data['negative_count'],
            'positive_ratio': pos_ratio,
            'negative_ratio': neg_ratio,
        })
    return results


def get_trading_days(db: NewsDatabase, start_date: str, end_date: str) -> List[str]:
    conn = db.get_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT DATE(published_at) as d, COUNT(*) as cnt
        FROM news
        WHERE DATE(published_at) >= ? AND DATE(published_at) <= ?
          AND related_stocks IS NOT NULL AND related_stocks != ''
        GROUP BY d HAVING cnt >= 10
        ORDER BY d
    """, (start_date, end_date))
    rows = cursor.fetchall()
    conn.close()
    return [row[0] for row in rows]


# â”€â”€â”€ 2ë‹¨ê³„: ì£¼ê°€ ì¼ê´„ í¬ë¡¤ë§ & ìºì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def collect_all_prices(daily_stats: Dict[str, List[Dict]], cache_path: str) -> Dict[str, any]:
    """ëª¨ë“  ì¢…ëª©ì˜ ì£¼ê°€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ìºì‹œ. ì´ë¯¸ ìºì‹œê°€ ìˆìœ¼ë©´ ë¡œë“œ."""
    if os.path.exists(cache_path):
        print(f"ğŸ’¾ ì£¼ê°€ ìºì‹œ ë¡œë“œ: {cache_path}")
        with open(cache_path, 'rb') as f:
            return pickle.load(f)

    # ë¹ˆì¶œ ì¢…ëª©ë§Œ í¬ë¡¤ë§ (ìƒìœ„ 300ê°œ ì œí•œ â€” ë©”ëª¨ë¦¬/ì‹œê°„ ê´€ë¦¬)
    from collections import Counter
    code_freq = Counter()
    for date, stocks in daily_stats.items():
        for s in stocks:
            code_freq[s['stock_code']] += 1
    
    MAX_STOCKS = 300
    all_codes = {code for code, _ in code_freq.most_common(MAX_STOCKS)}

    print(f"ğŸ“ˆ {len(all_codes)}ê°œ ì¢…ëª© ì£¼ê°€ í¬ë¡¤ë§ ì¤‘ (ì „ì²´ {len(code_freq)}ê°œ ì¤‘ ìƒìœ„ ë¹ˆì¶œ, ìºì‹œ ì—†ìŒ)...")
    fetcher = PriceFetcher()
    price_cache = {}
    
    for i, code in enumerate(sorted(all_codes)):
        if (i + 1) % 50 == 0 or i == 0:
            print(f"   [{i+1}/{len(all_codes)}] {code}...")
        try:
            time.sleep(0.15)
            df = fetcher.get_daily_price(code, pages=3)  # ~30ì¼ì¹˜
            price_cache[code] = df
        except Exception as e:
            logger.warning(f"ì£¼ê°€ ì¡°íšŒ ì‹¤íŒ¨: {code} - {e}")
            price_cache[code] = None

    # ìºì‹œ ì €ì¥
    with open(cache_path, 'wb') as f:
        pickle.dump(price_cache, f)
    print(f"   ìºì‹œ ì €ì¥: {cache_path}")
    return price_cache


def get_returns(price_cache: Dict, stock_code: str, signal_date: str) -> Dict[int, Optional[float]]:
    """ìºì‹œëœ ì£¼ê°€ì—ì„œ ìˆ˜ìµë¥  ê³„ì‚°"""
    df = price_cache.get(stock_code)
    if df is None or df.empty:
        return {d: None for d in HOLDING_DAYS}

    df = df.copy()
    df['ë‚ ì§œ'] = df['ë‚ ì§œ'].dt.normalize()
    df = df.sort_values('ë‚ ì§œ').reset_index(drop=True)
    signal_dt = datetime.strptime(signal_date, '%Y-%m-%d')

    future_days = df[df['ë‚ ì§œ'] > signal_dt]
    if future_days.empty:
        return {d: None for d in HOLDING_DAYS}

    entry_price = future_days.iloc[0]['ì‹œê°€']
    if entry_price is None or entry_price <= 0:
        return {d: None for d in HOLDING_DAYS}

    results = {}
    for hd in HOLDING_DAYS:
        if hd <= len(future_days):
            exit_price = future_days.iloc[hd - 1]['ì¢…ê°€']
            results[hd] = (exit_price - entry_price) / entry_price if exit_price and exit_price > 0 else None
        else:
            results[hd] = None
    return results


# â”€â”€â”€ 3ë‹¨ê³„: ìˆ˜ìµë¥  ë§¤íŠ¸ë¦­ìŠ¤ ì‚¬ì „ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def precompute_returns(daily_stats: Dict, price_cache: Dict) -> Dict[Tuple[str, str], Dict[int, Optional[float]]]:
    """(date, stock_code) â†’ {hd: return} ë§¤í•‘ì„ ì‚¬ì „ê³„ì‚°"""
    print("ğŸ“ ìˆ˜ìµë¥  ì‚¬ì „ê³„ì‚° ì¤‘...")
    returns_map = {}
    total = sum(len(stocks) for stocks in daily_stats.values())
    done = 0
    
    for date, stocks in daily_stats.items():
        for s in stocks:
            code = s['stock_code']
            returns_map[(date, code)] = get_returns(price_cache, code, date)
            done += 1
            if done % 500 == 0:
                print(f"   [{done}/{total}]")
    
    print(f"   {len(returns_map)}ê±´ ì™„ë£Œ")
    return returns_map


# â”€â”€â”€ 4ë‹¨ê³„: Grid Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def grid_search_buy(daily_stats: Dict, returns_map: Dict, benchmark_returns: Dict[int, float]):
    """BUY ì„ê³„ê°’ grid search"""
    print("\nğŸ” BUY ì„ê³„ê°’ Grid Search...")
    
    combos = list(product(
        BUY_GRID['avg_sentiment'],
        BUY_GRID['avg_overall'],
        BUY_GRID['news_count'],
        BUY_GRID['positive_ratio'],
    ))
    print(f"   {len(combos)}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸")

    results = []
    for sent_th, overall_th, count_th, ratio_th in combos:
        # ì´ ì¡°í•©ìœ¼ë¡œ ì„ íƒë˜ëŠ” ì¢…ëª©ë“¤
        selected = []
        for date, stocks in daily_stats.items():
            for s in stocks:
                if (s['avg_sentiment'] > sent_th
                    and s['avg_overall'] > overall_th
                    and s['news_count'] >= count_th
                    and s['positive_ratio'] >= ratio_th
                    and s['positive_count'] > s['negative_count']):
                    ret = returns_map.get((date, s['stock_code']))
                    if ret:
                        selected.append(ret)

        if len(selected) < 10:  # ìµœì†Œ ìƒ˜í”Œ ìˆ˜
            continue

        # ë³´ìœ ê¸°ê°„ë³„ í†µê³„
        stats = {}
        best_excess = -999
        for hd in HOLDING_DAYS:
            rets = [r[hd] for r in selected if r.get(hd) is not None]
            if not rets:
                continue
            avg_ret = sum(rets) / len(rets)
            hit_rate = sum(1 for r in rets if r > 0) / len(rets)
            excess = avg_ret - benchmark_returns.get(hd, 0)
            stats[hd] = {
                'n': len(rets), 'avg': avg_ret, 'hit_rate': hit_rate, 'excess': excess
            }
            if excess > best_excess:
                best_excess = excess

        if stats:
            results.append({
                'sentiment': sent_th, 'overall': overall_th,
                'count': count_th, 'ratio': ratio_th,
                'stats': stats, 'best_excess': best_excess,
                'n': len(selected),
            })

    return results


def grid_search_sell(daily_stats: Dict, returns_map: Dict, benchmark_returns: Dict[int, float]):
    """SELL ì„ê³„ê°’ grid search"""
    print("\nğŸ” SELL ì„ê³„ê°’ Grid Search...")
    
    combos = list(product(
        SELL_GRID['avg_sentiment'],
        SELL_GRID['avg_overall'],
        SELL_GRID['news_count'],
        SELL_GRID['negative_ratio'],
    ))
    print(f"   {len(combos)}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸")

    results = []
    for sent_th, overall_th, count_th, neg_ratio_th in combos:
        selected = []
        for date, stocks in daily_stats.items():
            for s in stocks:
                if (s['avg_sentiment'] < sent_th
                    and s['avg_overall'] < overall_th
                    and s['news_count'] >= count_th
                    and s['negative_ratio'] >= neg_ratio_th
                    and s['negative_count'] > s['positive_count']):
                    ret = returns_map.get((date, s['stock_code']))
                    if ret:
                        selected.append(ret)

        if len(selected) < 5:
            continue

        stats = {}
        best_excess = -999
        for hd in HOLDING_DAYS:
            rets = [r[hd] for r in selected if r.get(hd) is not None]
            if not rets:
                continue
            avg_ret = sum(rets) / len(rets)
            hit_rate = sum(1 for r in rets if r < 0) / len(rets)  # SELLì€ í•˜ë½ì´ ì ì¤‘
            # SELL ì´ˆê³¼ìˆ˜ìµ = ë²¤ì¹˜ë§ˆí¬ ìˆ˜ìµ - SELL ì¢…ëª© ìˆ˜ìµ (í•˜ë½í• ìˆ˜ë¡ ì¢‹ìŒ)
            excess = benchmark_returns.get(hd, 0) - avg_ret
            stats[hd] = {
                'n': len(rets), 'avg': avg_ret, 'hit_rate': hit_rate, 'excess': excess
            }
            if excess > best_excess:
                best_excess = excess

        if stats:
            results.append({
                'sentiment': sent_th, 'overall': overall_th,
                'count': count_th, 'neg_ratio': neg_ratio_th,
                'stats': stats, 'best_excess': best_excess,
                'n': len(selected),
            })

    return results


def calc_benchmark(daily_stats: Dict, returns_map: Dict) -> Dict[int, float]:
    """ë²¤ì¹˜ë§ˆí¬: ë‰´ìŠ¤ê°€ ìˆëŠ” ëª¨ë“  ì¢…ëª©ì˜ í‰ê·  ìˆ˜ìµë¥ """
    all_rets = {hd: [] for hd in HOLDING_DAYS}
    for date, stocks in daily_stats.items():
        for s in stocks:
            ret = returns_map.get((date, s['stock_code']))
            if ret:
                for hd in HOLDING_DAYS:
                    if ret.get(hd) is not None:
                        all_rets[hd].append(ret[hd])
    
    benchmark = {}
    for hd in HOLDING_DAYS:
        if all_rets[hd]:
            benchmark[hd] = sum(all_rets[hd]) / len(all_rets[hd])
        else:
            benchmark[hd] = 0.0
    return benchmark


# â”€â”€â”€ 5ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_top_results(results: List[Dict], signal_type: str, benchmark: Dict, top_n: int = 10):
    """ìƒìœ„ ê²°ê³¼ ì¶œë ¥"""
    # ê° ë³´ìœ ê¸°ê°„ë³„ë¡œ ìµœì  ì¡°í•© ì¶œë ¥
    for hd in HOLDING_DAYS:
        # í•´ë‹¹ ë³´ìœ ê¸°ê°„ excess ê¸°ì¤€ ì •ë ¬
        valid = [r for r in results if hd in r['stats']]
        valid.sort(key=lambda x: x['stats'][hd]['excess'], reverse=True)

        if not valid:
            continue

        print(f"\n{'='*70}")
        if signal_type == 'BUY':
            print(f"  ğŸ“ˆ BUY ìµœì  ì„ê³„ê°’ TOP {min(top_n, len(valid))} â€” {hd}ì¼ ë³´ìœ ")
        else:
            print(f"  ğŸ“‰ SELL ìµœì  ì„ê³„ê°’ TOP {min(top_n, len(valid))} â€” {hd}ì¼ ë³´ìœ ")
        print(f"  ë²¤ì¹˜ë§ˆí¬ {hd}ì¼ í‰ê· : {benchmark[hd]*100:+.2f}%")
        print(f"{'='*70}")

        for i, r in enumerate(valid[:top_n]):
            s = r['stats'][hd]
            if signal_type == 'BUY':
                print(f"  #{i+1}: sentiment>{r['sentiment']:.2f}, overall>{r['overall']:.1f}, "
                      f"count>={r['count']}, pos_ratio>={r['ratio']:.1f}")
            else:
                print(f"  #{i+1}: sentiment<{r['sentiment']:.2f}, overall<{r['overall']:.2f}, "
                      f"count>={r['count']}, neg_ratio>={r['neg_ratio']:.1f}")
            print(f"      {hd}ì¼ ì ì¤‘ë¥  {s['hit_rate']*100:.1f}%, "
                  f"í‰ê·  {s['avg']*100:+.2f}%, "
                  f"ì´ˆê³¼ìˆ˜ìµ {s['excess']*100:+.2f}%p "
                  f"(n={s['n']})")


def print_summary_table(results: List[Dict], signal_type: str, benchmark: Dict):
    """ì „ ë³´ìœ ê¸°ê°„ì— ê±¸ì³ ì•ˆì •ì ìœ¼ë¡œ ì¢‹ì€ ì¡°í•© ì°¾ê¸°"""
    # ëª¨ë“  ë³´ìœ ê¸°ê°„ì˜ ì´ˆê³¼ìˆ˜ìµ í•©ê³„ ê¸°ì¤€
    scored = []
    for r in results:
        total_excess = 0
        valid_periods = 0
        for hd in HOLDING_DAYS:
            if hd in r['stats']:
                total_excess += r['stats'][hd]['excess']
                valid_periods += 1
        if valid_periods >= 3:  # ìµœì†Œ 3ê°œ ë³´ìœ ê¸°ê°„ ë°ì´í„°
            scored.append((total_excess / valid_periods, r))
    
    scored.sort(key=lambda x: x[0], reverse=True)

    print(f"\n{'='*70}")
    print(f"  ğŸ† {signal_type} ì¢…í•© ìµœì  (ì „ ë³´ìœ ê¸°ê°„ í‰ê·  ì´ˆê³¼ìˆ˜ìµ ê¸°ì¤€) TOP 10")
    print(f"{'='*70}")

    for i, (avg_excess, r) in enumerate(scored[:10]):
        if signal_type == 'BUY':
            print(f"\n  #{i+1}: sentiment>{r['sentiment']:.2f}, overall>{r['overall']:.1f}, "
                  f"count>={r['count']}, pos_ratio>={r['ratio']:.1f}")
        else:
            print(f"\n  #{i+1}: sentiment<{r['sentiment']:.2f}, overall<{r['overall']:.2f}, "
                  f"count>={r['count']}, neg_ratio>={r['neg_ratio']:.1f}")
        
        for hd in HOLDING_DAYS:
            if hd in r['stats']:
                s = r['stats'][hd]
                print(f"      {hd:2d}ì¼: ì ì¤‘ë¥  {s['hit_rate']*100:5.1f}%  "
                      f"í‰ê·  {s['avg']*100:+6.2f}%  "
                      f"ì´ˆê³¼ {s['excess']*100:+6.2f}%p  (n={s['n']})")


# â”€â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description='NewsQuant ì„ê³„ê°’ ìµœì í™”')
    parser.add_argument('--start', type=str, default='2025-12-12')
    parser.add_argument('--end', type=str, default='2026-02-06')
    parser.add_argument('--db', type=str, default=str(PROJECT_ROOT / 'news_data.db'))
    parser.add_argument('--no-cache', action='store_true', help='ì£¼ê°€ ìºì‹œ ë¬´ì‹œ')
    parser.add_argument('--top', type=int, default=10)
    args = parser.parse_args()

    cache_path = str(PROJECT_ROOT / 'scripts' / 'price_cache.pkl')
    if args.no_cache and os.path.exists(cache_path):
        os.remove(cache_path)

    print(f"ğŸš€ NewsQuant ì„ê³„ê°’ ìµœì í™”")
    print(f"   ê¸°ê°„: {args.start} ~ {args.end}")
    print(f"   ë³´ìœ  ê¸°ê°„: {HOLDING_DAYS}ì¼\n")

    # 1) ì¢…ëª© í†µê³„ ì¶”ì¶œ
    db = NewsDatabase(args.db)
    daily_stats = extract_all_stock_stats(db, args.start, args.end)

    # ê²€ì¦ìš©: ë§ˆì§€ë§‰ max(HOLDING_DAYS)ì¼ ì œì™¸
    all_dates = sorted(daily_stats.keys())
    max_hold = max(HOLDING_DAYS)
    if len(all_dates) > max_hold:
        cutoff_dates = set(all_dates[-max_hold:])
        signal_stats = {d: v for d, v in daily_stats.items() if d not in cutoff_dates}
    else:
        signal_stats = daily_stats
    print(f"   ì‹œê·¸ë„ ê²€ì¦ ëŒ€ìƒ: {len(signal_stats)}ì¼ (ë§ˆì§€ë§‰ {max_hold}ì¼ ì œì™¸)")

    # 2) ì£¼ê°€ í¬ë¡¤ë§ (ì „ì²´ daily_stats ê¸°ì¤€ â€” ìˆ˜ìµë¥  ê³„ì‚°ì— í•„ìš”)
    price_cache = collect_all_prices(daily_stats, cache_path)

    # 3) ìˆ˜ìµë¥  ì‚¬ì „ê³„ì‚°
    returns_map = precompute_returns(signal_stats, price_cache)

    # 4) ë²¤ì¹˜ë§ˆí¬
    benchmark = calc_benchmark(signal_stats, returns_map)
    print(f"\nâš–ï¸  ë²¤ì¹˜ë§ˆí¬ (ì „ì²´ ë‰´ìŠ¤ ì¢…ëª© í‰ê· ):")
    for hd in HOLDING_DAYS:
        print(f"   {hd}ì¼: {benchmark[hd]*100:+.3f}%")

    # 5) Grid Search
    buy_results = grid_search_buy(signal_stats, returns_map, benchmark)
    sell_results = grid_search_sell(signal_stats, returns_map, benchmark)

    # 6) ê²°ê³¼ ì¶œë ¥
    print_summary_table(buy_results, 'BUY', benchmark)
    print_summary_table(sell_results, 'SELL', benchmark)

    # ë³´ìœ ê¸°ê°„ë³„ TOPë„ ì¶œë ¥
    for hd in [5, 7, 10]:  # ê°€ì¥ ìœ ì˜ë¯¸í•œ ê¸°ê°„ë§Œ
        print_top_results(buy_results, 'BUY', benchmark, args.top)
        print_top_results(sell_results, 'SELL', benchmark, args.top)
        break  # í•œë²ˆë§Œ (ì „ì²´ ê¸°ê°„ ë‹¤ ì¶œë ¥ë¨)

    print(f"\nâœ… ì™„ë£Œ! Grid search: BUY {len(buy_results)}ê°œ, SELL {len(sell_results)}ê°œ ìœ íš¨ ì¡°í•©")


if __name__ == '__main__':
    main()
